---
title: "Efficacy-Toxicity design (EffTox design)"
author: "Ziyan Wang"
date: "02/2022"
output:
  # html_document: default
  pdf_document: default
# runtime: shiny

---


# Introduction to phase I-II design

EffTox design is a phase I-II design which combine phase I and phase II into one trial. In phase I-II design, we will record both toxicity (phase I) and efficacy (phase II) data from all previous patients to make decision and select the most promising dose for the next cohort. 

### Elements of Phase I-II designs 
Denote the set of treatment regimes to be evaluated in a trial by $R=\{\rho_0,\rho_1,...,\rho_k\}$, and the multivariate outcome $Y$,
According to Yuan's book, phase I-II designs all include the following elements:
1. In each round of treatment, effects of each treatment regime on outcome $Y$, characterizing both efficacy and toxicity are evaluated. Based on these effects, we will select a best arm (dose) for the next cohort. 
2.Patients are enrolled and treated in successive cohorts (size = 1, 2 or 3). The treatment regime $\rho$ is chosen adaptively for each cohort from $R$ using the data ($\rho, Y$) from all previous patients. 
3. The adaptive decisions are based on an explicit criterion function $\phi(\rho, D_n)$, where $D_n$ is the data observed from first n patients. This function quantifies the risk-benefit trade-off of each $\rho$ being considered. 
4. The admissibility rules are often imposed to protect patients enrolled in the trial from unacceptably toxic or inefficacious regimes. 
5. The probability model is Bayesian, and decision criteria are based on posterior quantities.
6. The rule "Do not skip an untried dose when escalating" is often imposed because the Bayesian model may be mis-specified. 
7. Computer simulation is used to establish the design's properties and to calibrate priors and design parameters on that basis. 

### Treatment regime and clinical outcomes 

For most phase I-II trials, the regime is simply the dose of a new agent which is chosen based on (dose, toxicity, efficacy) data from all previous patients. The undesirable outcome toxicity is defined in terms of different adverse events at specified grades of severity. Efficacy is a desirable outcome which characterize an early anti-disease effect. They are usually defined as binary outcomes, although they can also be ordinal categorical (Phase I: Quasi-CRM) or time to event variable (Phase I: TiTe-CRM or TiTe-Boin). Each design will consider regimes $\rho$ that take one of the following forms: 
1. The dose d of a single agent administrate either alone or in combination with other agents that are not varied; 
2. The dose (d1, d2) of two agents given in combination; 
3. The dose (d1, d2) of a single agent given to a patient in two successive cycles; 
4. A combination (d, s) where d is the per-administration dose and s = ($s_1,s_2,...s_m$) is the schedule of administration times. 
The effects of each treatment regime $\rho$ on patients are evaluated in terms of outcome $Y$. For most phase I-II design, Y is a pair ($Y_E, Y_T$) of binary indicators of efficacy and toxicity. They can also be ordinal categorical variables. For example, $Y_E$ may have four possible values: Progressive Disease (PD: 0), Stable Disease (SD: 1), Partial Response (PR: 2), and Complete Response (CR: 3). Similarly, toxicity may have several levels: None (N: 0), Moderate (M: 1), High (H: 2) and Severe (S: 3). \textcolor{red}{This week,  I will focus on bivariate binary outcomes} ($Y_E, Y_T$). 

### Sequentially adaptive decision making 

Randomization is a simple and unbiased method to compare the effects between regimes. However, in most early phase trials, randomization will be unethical since some regimes may be unacceptably toxic. For example, the toxicity probability $\pi_T(d_k)$ increases with regime: dose $d_k$. In phase I study, the efficacy ($\pi_E$) is also assumed to increased with dose. The common phase I problem is to identify a dose that has acceptable toxicity probability. 
Phase I-II designs assume explicit models for $\pi_T$ and $\pi_E$. The goal is to select a dose with acceptably low toxicity with acceptably high efficacy. Randomization is also not ethical in phase I-II trial because a dose can be unacceptably toxic or unacceptably inefficacious. This motivates the sequentially adaptive designs. 
Assuming that the distribution of Y for each patient received regime $\rho$ is $p(Y|\rho,\theta)$. The prior is $p(\theta| \tilde \theta)$, where $\theta$ is the model parameter vector and $\tilde \theta$ is a vector of fixed hyperparameters. The data observed from first n patients is represented by $$D_n=\{(\rho_1,Y_1),...,(\rho_n,Y_n)\},$$ where $\rho_n$ is the regime used to treat the $n^{th}$ patient. The likelihood for n patients is $$L_n(D_n|\theta)=\prod^n_{i=1} p(Y_i|\rho_i,\theta).$$ The posterior distribution is $$p_n(\theta|D_n,\tilde \theta) \propto L_n(D_n|\theta)p(\theta| \tilde \theta).$$ According to Bayes Law, the posterior of $(n+1)^{th}$ iteration is $$p_n(\theta|D_n,\tilde \theta)p(Y_{n+1}|\rho_{n+1},\theta) \propto \{p(\theta| \tilde \theta) \prod^n_{i=1}p(Y_i|\rho_i,\theta)\} p(Y_{n+1}|\rho_{n+1},\theta)$$ $$=p_n(\theta|D_n,\tilde \theta)\prod^{n+1}_{i=1}p(Y_i|\rho_i,\theta).$$ \textcolor{red}{We can establish the prior based on effective sample size.} 
For cohort of size 1, the decision process for moving from n to n+1 iteration is given by the sequence of mappings $$D_n \rightarrow p_n(\theta|D_n,\tilde \theta) \rightarrow \rho_{n+1} \rightarrow Y_{n+1} \rightarrow D_{n+1}.$$ This process is repeated until the end of trial, which could be reaching the maximum sample size $N$ or maximum trial duration, or because trial is stopped early. For cohort size c > 1, we will jump from $n \rightarrow n+c$ at each step. For example, when c = 3, $\rho_{n+1}=\rho_{n+2}=\rho_{n+3}$ and $Y_{n+1},Y_{n+2},Y_{n+3}$ must be observed before making decision for the next cohort. 

### Risk-Benefit trade-off 

In Eff-Tox design we will firstly set an upper limit to exclude unacceptably toxic doses and a lower limit to exclude unacceptably inefficacious doses. For example, if 40% is the upper limit, the posterior probability criterion to declare a regime $\rho$ to be unacceptably toxic is $$Pr\{\pi_T(\rho,\theta)>0.4|D_n\}>0.9.$$ This is similar to unacceptably inefficacious criterion. The set of regime having both acceptable toxicity and efficacy based on $D_n$ is called admissible set, $A_n$. Then, we will define a trade-off function $\phi(\pi_E,\pi_T)$ to define how toxicity changes with efficacy. At each decision, the posterior mean toxicity and efficacy of each dose k will be calculated which are $\mu_{E,k,n}=E\{\pi_E(d_k,\theta)|D_n\}$ and $\mu_{T,k,n}=E\{\pi_T(d_k,\theta)|D_n\}$. The dose in the admissible set $A_n$ maximizing $\phi(\mu_{E,k,n},\mu_{T,k,n})$ will be chosen to be the optimal dose. 

All the theory will be described in detail in the next part. 

# Eff-Tox design in details
The Efficacy-Toxicity trade off based design has three basic components. The first component is two Bayesian models for both efficacy and toxicity with respect to doses. The second component consists two posterior probability criteria deciding which doses are acceptable. Denoting the outcome probability pair $\pi = (\pi_E,\pi_T)$. One acceptable criteria is based on the lower limit of efficacy ${\underline{\pi}_E}$. The other acceptable criteria is based on the upper limit of toxicity ${\underline{\pi}_T}$. The third component is the efficacy-toxicity trade-off contours that partition the two_dimensional domain $[0,\;1]^2$ for all possible outcome pair $\pi$. The contours quantifies the desirability of each dose. The contours are obtained by constructing a target trade off contour which is defined by several equally desirable outcome pairs $\pi^*$. These equally desirable pairs are initially elicited from the physician. Now, i will start to describe details of these components.

## Probability model

The bivariate binary outcomes $Y=(Y_E,Y_T)$ have four possible events: (0,0),(0,1),(1,0),(1,1). The best possible outcome is  $Y=(1,0)$, which is efficacy without toxicity. The worst possible outcome is $Y=(0,1)$, which is toxicity without efficacy. The outcome $Y=(0,0)$ means neither event occurs. The outcome $Y=(1,1)$ means both efficacy and toxicity occur - "success with a price".
Thall et al (2008) assumed marginal logistic models for toxicity and efficacy. $$\pi_{Event,k}(\theta_{Event})=logit^{-1}\{\eta_{Event,k}(\theta_{Event})\}\;for\; Event=E,T,$$ 
$$\eta_{E,k}(\theta_E)=\mu_E+\beta_{E,1}x_k+\beta_{E,2}x_k^2,$$
$$\eta_{T,k}(\theta_T)=\mu_T+\beta_{T}x_k.$$
where $\eta_{Event,k}$ is the linear terms of logistic models, $x_k$ is the standardized doses for $k^{th}$ real dose, $\theta_E=(\mu_E,\beta_{E,1},\beta_{E,2})$ and $\theta_T=(\mu_T,\beta_{T})$. Given K real doses $d_1<d_2<...<d_k$, the standardized doses was defined as $$x_k=log(d_k)-K^{-1}\sum_{r=1}^K log(d_r),\; k=1,...,K.$$ The model requires $\beta_{T,1}>0$ to make sure that $\pi_{T,k}(\theta_T)$ increases with dose, which is the case with cytotoxic agents. Bretz et al.(2005) gives various forms of $\pi_{Event}(\theta_{Event})$ that may be used in various phase I-II settings. Given the marginal probabilities, the bivariate distribution for $[Y_E,Y_T|x_k]$is defined using a copula (Nelsen, 2006). The joint probability is $$\pi(a,b|x_k,\theta)=Pr(Y_E=a,Y_T=b|x_k,\theta).$$ After suppress $x_k$ and $\theta_{Event}$, the Fairlie-Gumbel-Morgenstern(FGM) coupla is used and is given by $$\pi(a,b)=\pi_E^a(1-\pi_E)^{1-a}\pi_T^b(1-\pi_T)^{1-b}+(-1)^{a+b}(\frac{e^\psi-1}{e^\psi+1})\pi_E(1-\pi_E)\pi_T(1-\pi_T),$$ where (a,b)= (0,0),(0,1),(1,0) or (1,1), $\psi$ is a real-valued association parameter. Thus, the overall model has six hyperparameters, the vector $\theta=(\theta_T,\theta_E,\psi)$. Assuming $D_n=\{(Y_i,x_{[i]}),i=1,...,n\}$ is the observed data of n patients, where $Y_i=(Y_{i,E},Y_{i,T})$ is the data of the $i^{th}$ patient. The likelihood is $$L(D_n|\theta)=\prod_{i=1}^n\pi(Y_i|x_{[i]},\theta)$$ and the posterior distribution of $\theta$ is $$p(\theta|D_n,\tilde \theta) \propto L(D_n|\theta)p(\theta|\tilde \theta),$$ where $\tilde \theta$ is a vector of fixed hyperparameters as defined previously.

## Admissible criteria for doses

Since it is likely that no dose is both acceptably safe and acceptably efficacious, the admissibility criteria is necessary. Let $\underline{\pi}_E$ be a fixed lower limit on $\pi_{E,k}(\theta_E)$ and $\bar{\pi}_T$ be a fixed upper limit on $\pi_{T,k}(\theta_T)$. Both of fixed limits are elicited from physician. These limits depends on the definitions of toxicity and efficacy and what is considered acceptable in the particular clinical setting. Let $p_E$ and $p_T$ be fixed lower probability cut-offs ranging from 0.05 to 0.2 in practice. Thall described an alternative way "unacceptable criteria" which seem to make more sense. Assuming $p_E=p_T=0.1$, the inadmissibility criteria is $$Pr\{\pi_{E,k}(\theta_E)<\underline{\pi}_E|D_n,\tilde \theta\}>1-p_E=0.9\\ 
Pr\{\pi_{T,k}(\theta_T)>\bar{\pi}_T|D_n,\tilde \theta\}>1-p_T=0.9.$$, which mean $x_k$ is unacceptable if it is either very likely (90%) to be ineffecacious or very likely (90%) to be too toxic.

## Trade-off contours

The trade off contour in EffTox program is constructed as follows. The target contour is determined by three user-specified equally desirable outcome probability pairs $$\pi_1^*=(\pi_{1,E}^*,0),\pi_2^*=(1,\pi_{2,T}^*) \;and\;\pi_3^*=(\pi_{3,E}^*\pi_{3,T}^*).$$ The initial value is specified by physician. However, as said in Yuan's book, the key point is that \textcolor{red}{contour C must be calibrated to be sufficiently steep so that a design with good OCs is obtained.} After observing a new outcome pair $Y$, the posterior distribution of vector of parameter will be updated. Thus, we can calculate the marginal posterior mean toxicity and efficacy probabilities $\mu_{Event,k,n}=E\{\pi_{Event,k}(\theta_{Event})|D_n\}$. After calculating the probability pair $(\pi_T,\pi_E)$, we can locate the pair point on the Efficacy-Toxicity trade off contour. Thall defined a desirability function of $\pi=(\pi_E,\pi_T)\in [0,1]^2$ given contour C which is defined as $$\phi(\pi)=1-||\pi-(1,0)||_p$$ $$=1-\{(\frac{\pi_E-1}{\pi_{1,E}^*-1})^p+(\frac{\pi_T-0}{\pi_{2,T}^*-0})^p\}^{1/p},$$ where $p>0$. The optimization target is to maximize $\phi(\pi)$ which can be seen as minimizing the distance from $\pi=(\pi_E,\pi_T)$ to the most desirable outcome pair (1,0). In other words, the closer $\pi$ is from the point (1,0), the more desirable the dose level is. To calculate the value of $\phi(\pi)$ for all possible probability pairs, \textcolor{red}{we need to obtain the value of p by solving the equation} $\phi(\pi_{E,3}^*,\pi_{T,3}^*)=0$ \textcolor{red}{using the bisection method}. Thus, given contour C and p, for each desirability $\delta$, the contour can be defined as $$C_\delta=\{\pi\in[0,1]^2:\phi(\pi)=\delta\}.$$ Thus, all $\pi$ on $C_\delta$ have desirability $\delta$, and the target contour is $C=C_0$ 

Here are the stan and R codes for Eff-Tox design.

<!-- Here is the shiny app for calculating p and plotting contour. -->
Here is the value of p and contour plot based on user defined $\pi^*$
```{r}
print(pval)

efftox_get_tox <- function(eff, util, p, eff1, tox2) {
    a = ((1 - eff) / (1 - eff1))
    return(tox2 * ((1 - util)^p - a^p)^(1 / p))
}

effgrid<-seq(0,1,length.out=1000)
    
toxval=sapply(utilitygrid,function(u) efftox_get_tox(eff = effgrid,util = u,p=pval,
                                                eff1=input[names(input)=="pi1E"],
                                                tox2=input[names(input)=="pi2T"]))
    
dataf=data.frame(effgrid=rep(effgrid,times=length(utilitygrid)),
                 toxval=as.numeric(toxval),
                 utival=rep(utilitygrid,each=length(effgrid)))
    
tox_vals_fix = efftox_get_tox(eff = effgrid,util = 0, pval, 
                              eff1=input[names(input)=="pi1E"],
                              tox2=input[names(input)=="pi2T"])

dataf2 = data.frame(effgrid=rep(effgrid,times=length(utilitygrid)),
                               toxval=rep(as.numeric(tox_vals_fix,each=length(utilitygrid))),
                               utivals = rep(0,1000,each=length(utilitygrid)))
    
    # plt=reactive({ggplot(data = dataf(),aes(x=effgrid,y=toxval,group=as.factor(utival)))+geom_line(size = 0.5, alpha = 0.25,col="red")+
    #     xlim(0,1)+ylim(0,1)+xlab('Prob(Efficacy)')+ylab('Prob(Toxicity)')+geom_line(data = dataf2(), size = 1,col="red")})
    

  ggplot(data = dataf,aes(x=effgrid,y=toxval,group=as.factor(utival)))+
  geom_line(size = 1, alpha = 0.25)+
  xlim(0,1)+ylim(0,1)+xlab('Prob(Efficacy)')+ylab('Prob(Toxicity)')+
  geom_line(aes(y=efftox_get_tox(effgrid,0,pval,
                                   eff1=input[names(input)=="pi1E"],
                                   tox2=input[names(input)=="pi2T"]),
                  x=effgrid),lwd=1.5,col="red")+
  geom_point(aes(x=input[1],y=0),col="blue")+
  geom_point(aes(x=1,y=input[2]),col="blue")+
  geom_point(aes(x=input[3],y=input[4]),col="blue")
```
Here is the stan code for eff-tox design, which draws samples of $\theta=(\theta_T,\theta_E,\psi)$ from posterior distribution. It also computes the posterior distribution of $\pi_{Event,k}(\theta_{Event}|D_n)$ and desirability. Thus, we can compare the posterior distribution of $\pi_{Event,k}$ with inadmissibility criteria to construct an admissible set of doses in which the admissible desirability will be calculated for dose recommendation.
```{stan output.var="Eff_Tox_design"}

functions{
  //Define the bivariate binary likelihood
  real logit_jointpdf_EffTox(real muE, real muT,
                             real betaT,real betaE1,real betaE2,real phi,
                             int N, int[] eff, int[] tox, int[] z, 
                             real[] coded_dose,real[] coded_dosesqu){
    real log_likelihood;
    log_likelihood=0;
    for (n in 1:N){
      //for each patient in N, calculate the likelihood function and sum the log likelihood
      real efficacy;
      real toxicity;
      real p;
      toxicity=inv_logit(muT+betaT*coded_dose[z[n]]);
      efficacy=inv_logit(muE+betaE1*coded_dose[z[n]]+betaE2*coded_dosesqu[z[n]]);
      
      p=efficacy^eff[n]*(1-efficacy)^(1-eff[n])*
        toxicity^tox[n]*(1-toxicity)^(1-tox[n])+
        (-1)^(eff[n]+tox[n])*((exp(phi)-1)/(exp(phi)+1))*
        efficacy*(1-efficacy)*toxicity*(1-toxicity);
      log_likelihood+=log(p);
    }
    return log_likelihood;
  }
}

data{
  //Fixed mean an sd of hyperparameters.
  //Prior can be calculated based on prior effective sample size (not very clear at this moment)
  real muE_mean;
  real muE_sd;
  
  real muT_mean;
  real muT_sd;
  
  real betaT_mean;
  real betaT_sd;
  
  real betaE1_mean;
  real betaE1_sd;
  
  real betaE2_mean;
  real betaE2_sd;
  
  real phi_mean;
  real phi_sd;
  
  // The value of p is determined by three equally desirable outcome pairs.
  // This should be calculated before doing HMC.
  real p;
  
  // Three equally desirable outcome pairs
  real eff1; //pi_1*=(eff1,0)
  real tox2; //pi_2*=(1,tox2)
  //pi_3*=(eff3,tox3)
  real eff3; 
  real tox3;
  
  //number of real doses
  int<lower=1> K;
  //vector of real doses
  real<lower=0> real_dose[K]; // Eg. 10mg/l,20mg/l,30mg/l
  //number of patients
  int<lower=0> N;
  //efficacy outcome of n patients
  int<lower=0, upper=1> eff[N];
  //toxicity outcome of n patients
  int<lower=0, upper=1> tox[N];
  //treatment used on nth patient
  int<lower=0, upper=K> z[N];
}

transformed data{
  //Calculate the standardized doses
  real mean_log_dose;  
  real coded_dose[K];
  real coded_dosesqu[K];
  mean_log_dose=0.0;
  for (k in 1:K)
    mean_log_dose=mean_log_dose+log(real_dose[k]);
  mean_log_dose=mean_log_dose/K;

  for (k in 1:K){
  coded_dose[k]=log(real_dose[k])-mean_log_dose;
  coded_dosesqu[k]=coded_dose[k]^2;
  }
}

parameters {
  //hyperparamters
  real muE;
  real muT;
  real betaT;
  real betaE1;
  real betaE2;
  real phi;
}

transformed parameters{
  //toxicity and efficacy probability estimates of each dose
  real<lower=0,upper=1> efficacy[K];
  real<lower=0,upper=1> toxicity[K]; 
  
  //calculate the desirability for decision making
  real desirability[K];
  for (k in 1:K){
  
  //distance_to_most_desirable_point (1,0) which is p(efficacy)=1, p(toxicity)=0
  real distance_to_most_desirable_point;
  
  toxicity[k]=inv_logit(muT+betaT*coded_dose[k]);
  efficacy[k]=inv_logit(muE+betaE1*coded_dose[k]+betaE2*coded_dosesqu[k]);
  
  distance_to_most_desirable_point=
  (((1-efficacy[k])/(1-eff1))^p+((toxicity[k]-0)/(tox2-0))^p)^(1/p);
  
  //calculate desirability function
  desirability[k]=1-distance_to_most_desirable_point;
  }
}

model {
  // prior
  muE~normal(muE_mean,muE_sd);
  muT~normal(muT_mean,muT_sd);
  betaT~normal(betaT_mean,betaT_sd);
  betaE1~normal(betaE1_mean,betaE1_sd);
  betaE2~normal(betaE2_mean,betaE2_sd);
  phi~normal(phi_mean,phi_sd);
  
  //likelihood
  target += logit_jointpdf_EffTox(muE,muT,betaT,betaE1,betaE2,phi,
                                  N, eff, tox, z, coded_dose, coded_dosesqu);
}
```

```{r}
##True toxicity and efficacy
True_Tox<-c(0.2,0.25,0.35,0.6)
True_Eff<-c(0.25,0.35,0.55,0.6)

real_dose<-c(20,40,60,80)
##Number of real doses
K=length(real_dose)

##Number of patients
MAX_N=60
cohort=3

#Admissibility criteria
lowerpi_E<-0.4
upperpi_T<-0.45
cutoffE=0.1
cutoffT=0.1


#Prior
#The target ESS in the book is 0.9
#Thus the priors are

muT_mean=-7.9593
muT_sd=3.5487

muE_mean=0.7367
muE_sd=2.5423
  
betaT_mean=1.5482
betaT_sd=3.5018
  
betaE1_mean=3.4181
betaE1_sd=2.4406

betaE2_mean=0
betaE2_sd=0.2
  
phi_mean=0
phi_sd=1

finalassign={}

for (s in 1:100){
  

eff <- array(0.0, 0)
tox<- array(0.0, 0)
z <- array(0.0, 0)

##Generating dataset with True prob

datasetE=matrix(rep(0),ncol = K+1,nrow = MAX_N) # Initializing the obs datasetE
datasetT=matrix(rep(0),ncol = K+1,nrow = MAX_N) # Initializing the obs datasetT

#Generating random data
for (q in 1:(MAX_N/cohort)){
  for (k in 1:K){
    datasetE[(cohort*q-cohort+1):(cohort*q),k]=rbinom(cohort,1,True_Eff[k])
    datasetT[(cohort*q-cohort+1):(cohort*q),k]=rbinom(cohort,1,True_Tox[k])
  }
}
#label the cohort number
datasetE[,K+1]=rep((1:(MAX_N/cohort)),each=cohort)
datasetT[,K+1]=rep((1:(MAX_N/cohort)),each=cohort)

start_dose=1
greedyassign=start_dose

TSselection=start_dose
criteriaresult=0

for (n in 1:(MAX_N/cohort)){
  
  if (n==1){
    z[(cohort*n-cohort+1):(cohort*n)]=rep(1,cohort)
#-------------------Apply arm selected-----------------
    eff[(cohort*n-cohort+1):(cohort*n)]=datasetE[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
    tox[(cohort*n-cohort+1):(cohort*n)]=datasetT[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
  }
   else if (sum(criteriaresult)>0){
    greedyassign=which.max(ifelse(criteriaresult,desirabilitymean,NA))
    z[(cohort*n-cohort+1):(cohort*n)]=rep(greedyassign,cohort)
  #-------------------Apply arm selected-----------------
    eff[(cohort*n-cohort+1):(cohort*n)]=datasetE[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
    tox[(cohort*n-cohort+1):(cohort*n)]=datasetT[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
    } 
  else{
    greedyassign=NA
    z[(cohort*n-cohort+1):(cohort*n)]=rep(greedyassign,cohort)
    break()
  }


##-----------------------------Compute posterior distribution based on current data

data=list(K = K, N = (cohort*n),
         eff = array(eff, dim = (cohort*n)), tox = array(tox, dim = (cohort*n)), z = array(z, dim = (cohort*n)),
         real_dose=real_dose,
#---------------------P and userm defined contour from shiny app efftox contour-----------
         p=pval,
         eff1=input[1],tox2=input[2],eff3=input[3],tox3=input[4],
#---------------------prior----------------------
         muT_mean=muT_mean, muT_sd=muT_sd,muE_mean=muE_mean,muE_sd=muE_sd,
         betaT_mean=betaT_mean,betaT_sd=betaT_sd,
         betaE1_mean=betaE1_mean,betaE1_sd=betaE1_sd,
         betaE2_mean=betaE2_mean,betaE2_sd=betaE2_sd,
         phi_mean=phi_mean,phi_sd=phi_sd)

# data=list(K = K, N = (cohort*n-cohort),
#          eff = array(eff, dim = (cohort*n-cohort)), tox = array(tox, dim = (cohort*n-cohort)), z = array(z, dim = (cohort*n-cohort)),
#          real_dose=real_dose,
# #---------------------P and userm defined contour from shiny app efftox contour-----------
#          p=pval,
#          eff1=input[1],tox2=input[2],eff3=input[3],tox3=input[4],
# #---------------------prior----------------------
#          muT_mean=muT_mean, muT_sd=muT_sd,muE_mean=muE_mean,muE_sd=muE_sd,
#          betaT_mean=betaT_mean,betaT_sd=betaT_sd,
#          betaE1_mean=betaE1_mean,betaE1_sd=betaE1_sd,
#          betaE2_mean=betaE2_mean,betaE2_sd=betaE2_sd,
#          phi_mean=phi_mean,phi_sd=phi_sd)

fit <- rstan::sampling(Eff_Tox_design, data = data, chains = 1, refresh=0,
                       warmup=2500, iter=5000)

toxicitysamples=rstan::extract(fit,'toxicity')[[1]]
efficacysamples=rstan::extract(fit,'efficacy')[[1]]
desirabilitysamples=rstan::extract(fit,'desirability')[[1]]
desirabilitymean=colMeans(desirabilitysamples)
#Constructing admissibility set

mindose=min(data$z)
maxdose=max(data$z)

criteriaresult=((colMeans(efficacysamples-lowerpi_E>0)>cutoffE) & 
                  (colMeans(toxicitysamples-upperpi_T<0)>cutoffT) &
                   sapply(1:K, function(nextdose) nextdose>=(mindose-1) & nextdose<=(maxdose+1)))

toxicitymean=colMeans(toxicitysamples)
efficacymean=colMeans(efficacysamples)


#-------------------Normal Eff-tox design selection-----------------------------
# if (sum(criteriaresult)>0){
#   greedyassign=which.max(ifelse(criteriaresult,desirabilitymean,NA))
#   z[(cohort*n-cohort+1):(cohort*n)]=rep(greedyassign,cohort)
# } else{
#   greedyassign=NA
#   z[(cohort*n-cohort+1):(cohort*n)]=rep(greedyassign,cohort)
#   break()
# }

#-------------------Thompson sampling selection-----------------------
# TSprob=table(factor(max.col(admissible_desirabilitysamples),
#                     levels=1:ncol(admissible_desirabilitysamples)))/dim(admissible_desirabilitysamples)[1]
# 
# TSselection=sample(K,1,replace=T,TSprob)
# z[n]=TSselection

# #-------------------Apply arm selected-----------------
# eff[(cohort*n-cohort+1):(cohort*n)]=datasetE[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
# tox[(cohort*n-cohort+1):(cohort*n)]=datasetT[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
}
finalassign=c(finalassign,greedyassign)
}


resultassign=finalassign
resultassign[is.na(resultassign)]="None"
resultmatrix=t(matrix(table(resultassign)))
colnames(resultmatrix)=c("1","2","3","4","None")

knitr::kable(resultmatrix,caption = "The 100 iteration simultion results of greedy selection")
```
The results for 100 simulation gives similar results as shown on the book. Then let's use a different selection criteria (Thompson sampling) to do this trial.
Here is the code for TS sampling. 
```{r}
##True toxicity and efficacy
True_Tox<-c(0.2,0.25,0.35,0.6)
True_Eff<-c(0.25,0.35,0.55,0.6)

real_dose<-c(20,40,60,80)
##Number of real doses
K=length(real_dose)

##Number of patients
MAX_N=60
cohort=3

#Admissibility criteria
lowerpi_E<-0.4
upperpi_T<-0.45
cutoffE=0.1
cutoffT=0.1


#Prior
#The target ESS in the book is 0.9
#Thus the priors are

muT_mean=-7.9593
muT_sd=3.5487

muE_mean=0.7367
muE_sd=2.5423
  
betaT_mean=1.5482
betaT_sd=3.5018
  
betaE1_mean=3.4181
betaE1_sd=2.4406

betaE2_mean=0
betaE2_sd=0.2
  
phi_mean=0
phi_sd=1

finalassignTS={}

for (s in 1:100){
  

eff <- array(0.0, 0)
tox<- array(0.0, 0)
z <- array(0.0, 0)

##Generating dataset with True prob

datasetE=matrix(rep(0),ncol = K+1,nrow = MAX_N) # Initializing the obs datasetE
datasetT=matrix(rep(0),ncol = K+1,nrow = MAX_N) # Initializing the obs datasetT

#Generating random data
for (q in 1:(MAX_N/cohort)){
  for (k in 1:K){
    datasetE[(cohort*q-cohort+1):(cohort*q),k]=rbinom(cohort,1,True_Eff[k])
    datasetT[(cohort*q-cohort+1):(cohort*q),k]=rbinom(cohort,1,True_Tox[k])
  }
}
#label the cohort number
datasetE[,K+1]=rep((1:(MAX_N/cohort)),each=cohort)
datasetT[,K+1]=rep((1:(MAX_N/cohort)),each=cohort)

start_dose=1
greedyassign=start_dose

TSselection=start_dose
criteriaresult=0

for (n in 1:(MAX_N/cohort)){
  
  if (n==1){
    z[(cohort*n-cohort+1):(cohort*n)]=rep(1,cohort)
#-------------------Apply arm selected-----------------
    eff[(cohort*n-cohort+1):(cohort*n)]=datasetE[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
    tox[(cohort*n-cohort+1):(cohort*n)]=datasetT[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
  }
  else{
    #-------------------Thompson sampling selection-----------------------
    if (sum(criteriaresult)>1){
      TSprob=table(factor(max.col(desirabilitysamples[,criteriaresult]),
                          levels=1:ncol(desirabilitysamples[,criteriaresult])))/dim(desirabilitysamples[,criteriaresult])[1]
      names(TSprob)=seq(1:K)[criteriaresult]
      TSselection=sample(as.numeric(names(TSprob)),1,replace=T,TSprob)
      z[(cohort*n-cohort+1):(cohort*n)]=rep(TSselection,cohort)
     #-------------------Apply arm selected-----------------
      eff[(cohort*n-cohort+1):(cohort*n)]=datasetE[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
      tox[(cohort*n-cohort+1):(cohort*n)]=datasetT[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
      }
    else if (sum(criteriaresult)==1){
      TSselection=which(criteriaresult==T)
      z[(cohort*n-cohort+1):(cohort*n)]=rep(TSselection,cohort)
      #-------------------Apply arm selected-----------------
      eff[(cohort*n-cohort+1):(cohort*n)]=datasetE[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
      tox[(cohort*n-cohort+1):(cohort*n)]=datasetT[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
      }
    else{
      TSselection=NA
      z[(cohort*n-cohort+1):(cohort*n)]=rep(greedyassign,cohort)
      break()
      }
  }


##-----------------------------Compute posterior distribution based on current data

data=list(K = K, N = (cohort*n),
         eff = array(eff, dim = (cohort*n)), tox = array(tox, dim = (cohort*n)), z = array(z, dim = (cohort*n)),
         real_dose=real_dose,
#---------------------P and userm defined contour from shiny app efftox contour-----------
         p=pval,
         eff1=input[1],tox2=input[2],eff3=input[3],tox3=input[4],
#---------------------prior----------------------
         muT_mean=muT_mean, muT_sd=muT_sd,muE_mean=muE_mean,muE_sd=muE_sd,
         betaT_mean=betaT_mean,betaT_sd=betaT_sd,
         betaE1_mean=betaE1_mean,betaE1_sd=betaE1_sd,
         betaE2_mean=betaE2_mean,betaE2_sd=betaE2_sd,
         phi_mean=phi_mean,phi_sd=phi_sd)

# data=list(K = K, N = (cohort*n-cohort),
#          eff = array(eff, dim = (cohort*n-cohort)), tox = array(tox, dim = (cohort*n-cohort)), z = array(z, dim = (cohort*n-cohort)),
#          real_dose=real_dose,
# #---------------------P and userm defined contour from shiny app efftox contour-----------
#          p=pval,
#          eff1=input[1],tox2=input[2],eff3=input[3],tox3=input[4],
# #---------------------prior----------------------
#          muT_mean=muT_mean, muT_sd=muT_sd,muE_mean=muE_mean,muE_sd=muE_sd,
#          betaT_mean=betaT_mean,betaT_sd=betaT_sd,
#          betaE1_mean=betaE1_mean,betaE1_sd=betaE1_sd,
#          betaE2_mean=betaE2_mean,betaE2_sd=betaE2_sd,
#          phi_mean=phi_mean,phi_sd=phi_sd)

fit <- rstan::sampling(Eff_Tox_design, data = data, chains = 1, refresh=0,
                       warmup=2500, iter=5000)

toxicitysamples=rstan::extract(fit,'toxicity')[[1]]
efficacysamples=rstan::extract(fit,'efficacy')[[1]]
desirabilitysamples=rstan::extract(fit,'desirability')[[1]]
desirabilitymean=colMeans(desirabilitysamples)
#Constructing admissibility set

mindose=min(data$z)
maxdose=max(data$z)

criteriaresult=((colMeans(efficacysamples-lowerpi_E>0)>cutoffE) & 
                  (colMeans(toxicitysamples-upperpi_T<0)>cutoffT) &
                   sapply(1:K, function(nextdose) nextdose>=(mindose-1) & nextdose<=(maxdose+1)))

toxicitymean=colMeans(toxicitysamples)
efficacymean=colMeans(efficacysamples)



# #-------------------Thompson sampling selection-----------------------
# if (sum(criteriaresult)>1){
#   TSprob=table(factor(max.col(desirabilitysamples[,criteriaresult]),
#                     levels=1:ncol(desirabilitysamples[,criteriaresult])))/dim(desirabilitysamples[,criteriaresult])[1]
#   names(TSprob)=seq(1:K)[criteriaresult]
#   TSselection=sample(as.numeric(names(TSprob)),1,replace=T,TSprob)
#   z[(cohort*n-cohort+1):(cohort*n)]=rep(TSselection,cohort)
# }
# else if (sum(criteriaresult)==1){
#   TSselection=which(criteriaresult==T)
#   z[(cohort*n-cohort+1):(cohort*n)]=rep(TSselection,cohort)
# }
# else{
#   TSselection=NA
#   z[(cohort*n-cohort+1):(cohort*n)]=rep(greedyassign,cohort)
#   break()
# }


# #-------------------Apply arm selected-----------------
# eff[(cohort*n-cohort+1):(cohort*n)]=datasetE[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
# tox[(cohort*n-cohort+1):(cohort*n)]=datasetT[(cohort*n-cohort+1):(cohort*n),z[(cohort*n)]]
}
finalassignTS=c(finalassignTS,TSselection)

}

resultassignTS=finalassignTS
resultassignTS[is.na(resultassignTS)]="None"
resultmatrixTS=t(matrix(table(resultassignTS)))
colnames(resultmatrixTS)=c("1","2","3","4","None")

knitr::kable(resultmatrixTS,caption = "The 100 iteration simultion results of TS selection")
```

